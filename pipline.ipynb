{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "Objective: Automate the process of collecting new data and saving it to a structured format.\n",
    "\n",
    "Steps:\n",
    "\n",
    "#### 1. Set up a Data Collection Mechanism:\n",
    "<ul>\n",
    "    <li>Schedule scripts to collect data periodically from sensors or external APIs.</li>\n",
    "    <li>Use tools like Apache Kafka or AWS Kinesis for real-time data streaming.</li>\n",
    "</ul>\n",
    "\n",
    "#### 2. Save Raw Data:\n",
    "<ul>\n",
    "    <li>Store the raw data in a cloud storage solution like AWS S3, Azure Blob Storage, or Google Cloud Storage.</li>\n",
    "    <li>Use a consistent naming convention and folder structure.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to collect new data\n",
    "def collect_data(api_url):\n",
    "    response = requests.get(api_url)\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Save raw data to CSV\n",
    "def save_raw_data(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "# Example usage\n",
    "api_url = 'http://example.com/api/data'\n",
    "df = collect_data(api_url)\n",
    "timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "save_raw_data(df, f'raw_data_{timestamp}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing\n",
    "\n",
    "Objective: Automate the cleaning and preprocessing steps.\n",
    "\n",
    "Steps:\n",
    "\n",
    "#### 1. Load Raw Data:\n",
    "<ul>\n",
    "<li>   Read the raw data from the storage.</li>\n",
    "</ul>\n",
    "\n",
    "#### 2. Cleaning Steps:\n",
    "<ul>\n",
    "<li> Convert timestamps. </li>\n",
    "<li>  Handle missing values.</li>\n",
    "<li>  Detect and handle outliers.</li>\n",
    "<li>  Normalize data.</li>\n",
    "</ul>\n",
    "\n",
    "#### 3. Save Cleaned Data:\n",
    "<ul>\n",
    "<li> Save the cleaned data back to the storage or a database.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load raw data\n",
    "def load_raw_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# Data cleaning function\n",
    "def clean_data(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df.fillna(method='linear', inplace=True)\n",
    "    # Add more cleaning steps as needed\n",
    "    return df\n",
    "\n",
    "# Save cleaned data\n",
    "def save_cleaned_data(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "# Example usage\n",
    "raw_data_path = 'raw_data.csv'\n",
    "cleaned_data_path = 'cleaned_data.csv'\n",
    "df = load_raw_data(raw_data_path)\n",
    "cleaned_df = clean_data(df)\n",
    "save_cleaned_data(cleaned_df, cleaned_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "Objective: Train and evaluate the model using the cleaned data.\n",
    "\n",
    "Steps:\n",
    "\n",
    "#### 1. Load Cleaned Data:\n",
    "<ul>\n",
    "<li>Read the cleaned data.</li>\n",
    "</ul>\n",
    "\n",
    "#### 2. Train the Model:\n",
    "\n",
    "<ul>\n",
    "<li>Split the data into training and validation sets.</li>\n",
    "<li>Train the model and evaluate its performance.</li>\n",
    "</ul>\n",
    "\n",
    "#### 3. Save the Model:\n",
    "\n",
    "<ul>\n",
    "<li>Save the trained model to a file for future use.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "# Load cleaned data\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Split data\n",
    "X = df.drop(columns=['Prod_kW'])\n",
    "y = df['Prod_kW']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "score = model.score(X_test, y_test)\n",
    "print(f'Model R^2 Score: {score}')\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, 'pv_production_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment and Inference Pipeline\n",
    "Objective: Automate the process of loading new data, cleaning it, and making predictions using the trained model.\n",
    "\n",
    "Steps:\n",
    "\n",
    "#### 1. Load New Data:\n",
    "\n",
    "Collect new data and save it as before.\n",
    "\n",
    "#### 2. Clean New Data:\n",
    "\n",
    "Apply the same cleaning steps to the new data.\n",
    "#### 3. Load the Model:\n",
    "\n",
    "Load the trained model from the file.\n",
    "#### 4. Make Predictions:\n",
    "Pass the cleaned new data to the model to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load new data\n",
    "new_data_path = 'new_data.csv'\n",
    "new_df = pd.read_csv(new_data_path)\n",
    "\n",
    "# Clean new data\n",
    "cleaned_new_df = clean_data(new_df)  # Reuse the clean_data function\n",
    "\n",
    "# Load model\n",
    "model = joblib.load('pv_production_model.pkl')\n",
    "\n",
    "# Make predictions\n",
    "X_new = cleaned_new_df.drop(columns=['Prod_kW'])\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Save predictions\n",
    "cleaned_new_df['Predicted_Prod_kW'] = predictions\n",
    "cleaned_new_df.to_csv('predicted_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring and Maintenance\n",
    "Objective: Continuously monitor the performance of the model and update it as necessary.\n",
    "\n",
    "Steps:\n",
    "\n",
    "#### 1. Monitor Model Performance:\n",
    "\n",
    "Track prediction accuracy and other relevant metrics.\n",
    "Set up alerts for significant deviations.\n",
    "\n",
    "#### 2. Update Model:\n",
    "\n",
    "Retrain the model periodically with new data to maintain accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_performance(actuals, predictions):\n",
    "    # Compare actual and predicted values\n",
    "    difference = actuals - predictions\n",
    "    mean_difference = difference.mean()\n",
    "    print(f'Mean Difference: {mean_difference}')\n",
    "    # Add more monitoring metrics as needed\n",
    "\n",
    "# Example usage\n",
    "actuals = cleaned_new_df['Prod_kW']\n",
    "predictions = cleaned_new_df['Predicted_Prod_kW']\n",
    "monitor_performance(actuals, predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
